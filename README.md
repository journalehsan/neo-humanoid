# ğŸ¤– Neo-Humanoid Project

### *An open-source, human-sized AI-driven robot built from the ground up â€” brain first.*

---

## ğŸ§  Overview

**Neo-Humanoid** is a 1.67 m tall, semi-autonomous humanoid robot designed to **learn, move, and react like a living creature**.
It combines **Rust-based real-time reflexes**, **distributed limb control**, and **multi-tier AI orchestration** (small and large language models) to bridge physical robotics and intelligent reasoning.

Inspired by **octopus neural systems** â€” each limb acts semi-independently while staying synchronized with a central brain.

---

## ğŸ¦¾ Key Features

| Layer                                   | Role                                                  | Technology                                                                    |
| --------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------------- |
| ğŸ¦µ **Tier 0 â€“ Reflex & Balance**        | Real-time motion, fall recovery, stair climbing       | **Rust**, CAN/RS-485, local IMU/foot sensors                                  |
| ğŸ§© **Tier 1 â€“ Orchestrator / Composer** | Fast reasoning, pattern calling, command routing      | **Rust + Tokio + gRPC + ROS 2 bridge**                                        |
| ğŸ§  **Tier 2 â€“ Deep Reasoning Models**   | Scene understanding, planning, language               | **Qwen 2.5 (7B)** for mid-level, **Qwen 3 / DeepSeek v3.1** for deep planning |
| ğŸ—£ **Speech & Hearing**                 | Whisper speech recognition, emotion-adaptive TTS      | **Whisper.cpp / Faster-Whisper**, **Coqui-TTS / Piper**                       |
| ğŸ® **Distributed Limb Control**         | Each limb MCU handles local reflexes and torque loops | **ESP32 / STM32**, `no_std` Rust firmware                                     |
| ğŸ”‹ **Body & Power Core**                | Battery bay + Jetson / RK3588 AI compute              | Smart power manager + safety cut-off                                          |
| ğŸŒˆ **Face & Emotion System**            | LED eyes, head servos, mouth sync                     | Expression mapped to emotion tags                                             |
| â˜ï¸ **Cloud Extension (optional)**       | Telepresence, memory, big VLMs                        | MQTT / WebRTC / REST                                                          |

---

## ğŸ§¬ Biological Inspiration

Neo's control architecture mimics **animal nervous systems**:

* **Reflex Layer:** Acts instantly (balance, avoid fall)
* **Muscle Memory:** Stores frequently used patterns for instant replay
* **Orchestrator Layer:** Decides *what* to do next
* **Deep Thought Layer:** Uses large AI models to analyze scenes and plan
* **Sensory Fusion:** Vision, sound, and touch combined for context-aware movement

Like a goldfish or octopus, Neo reuses learned motion sequences for fast, zero-latency reaction.

---

## ğŸ›  Tech Stack

* **Languages:** Rust ğŸ¦€ (core, control, orchestrator), Python (AI tools)
* **Frameworks:** ROS 2 (communication), gRPC, Tokio async runtime
* **AI Models:**

  * Whisper (speech recognition)
  * Qwen 2.5 7B â†’ fast reasoning
  * Qwen 3 / DeepSeek v3.1 â†’ deep reasoning
  * Coqui-TTS / Piper (speech synthesis)
* **Hardware:**

  * Jetson Orin Nano / RK3588 Pro (main AI board)
  * ESP32 / STM32 for limbs
  * Aluminum + flexible TPU frame, cotton padding
  * RGB + IR cameras, ToF sensors, IMUs, mic array
  * 24â€“48 V Li-ion battery system

---

## ğŸ§© System Architecture (high-level)

```
[User Voice] 
   â†“
[Whisper] â†’ [Orchestrator AI (Rust)]
                â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Tier 0: Reflex Layer (MCUs, Rust no_std) â”‚
   â”‚ Tier 1: Orchestrator / Pattern Engine    â”‚
   â”‚ Tier 2: Deep Models (Qwen / DeepSeek)    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
        [Motors / Servos / Sensors]
```

---

## ğŸ’¡ Development Roadmap

| Phase | Months | Goal                                                               |
| ----- | ------ | ------------------------------------------------------------------ |
| ğŸ§© 1  | 1â€“2    | Build **brain simulation**: Whisper + Orchestrator + TTS (no body) |
| âš™ï¸ 2  | 3â€“4    | Prototype **limb control boards**, reflex motion in Rust           |
| ğŸ‘ 3  | 5â€“6    | Add **head**: RGB/IR cameras, mic array, IMU                       |
| ğŸ”‹ 4  | 7â€“8    | Build **torso**: battery + AI board + power manager                |
| ğŸ¦¿ 5  | 9â€“10   | Assemble full **1.67 m frame**, walking & balance                  |
| ğŸš€ 6  | 11â€“12  | Integrate, polish, and **open-source release**                     |

---

## ğŸ§  Behavior Examples

* React to "Hey Neo" (wake-word)
* Walk to user and wave
* Look toward a voice source
* Pick up a recognized object (e.g., *"C++ Tutorial"* book)
* Repeat learned tasks from pattern memory
* Auto-recover from back-tilt or stair misstep in < 100 ms

---

## ğŸ”“ Open Source Vision

Neo-Humanoid will be released under a permissive license (likely **Apache 2.0** or **MIT**) so developers and makers can:

* Build their own units
* Improve hardware designs
* Train and share new behavior patterns
* Connect to alternative AI models or cloud services

Community goal: **make humanoid robotics affordable, ethical, and developer-friendly**.

---

## ğŸ§­ Future Ideas

* On-device learning (reinforce good motion sequences)
* Vision-language grounding (see â†’ understand â†’ act)
* Human emotion mirroring
* Home and lab assistant skills
* Optional solar charging dock

---

## ğŸ“¦ Repository Layout

```
neo-humanoid/
â”œâ”€â”€ orchestrator/          # Rust orchestration engine
â”œâ”€â”€ reflex/                # Real-time limb & balance control
â”œâ”€â”€ llm_client/            # Qwen / DeepSeek connectors
â”œâ”€â”€ whisper_tts/           # Speech I/O (Whisper + Coqui)
â”œâ”€â”€ patterns/              # Motion JSON / DSL files
â”œâ”€â”€ hardware/              # CAD + wiring + MCU firmware
â”‚   â”œâ”€â”€ cad/               # 3D models and mechanical designs
â”‚   â”œâ”€â”€ wiring/            # Electrical schematics
â”‚   â””â”€â”€ firmware/          # MCU firmware for limbs
â”œâ”€â”€ docs/                  # Hardware + software docs
â””â”€â”€ LICENSE
```

---

## â¤ï¸ Credits

* Concept & architecture: **Ehsan Tork**
* AI assistance: **GPT-5** (OpenAI)
* Inspired by: **octopus neural systems** and **goldfish pattern memory**

---

## ğŸš€ Getting Started

Coming soon! Check the `docs/` folder for installation and setup guides as the project develops.

---

**Status:** ğŸš§ Early development â€” contributions and ideas welcome!
